Evaluaciones para el modeloLibSVM		2		The type of SVM to use.2014-11-26-22:28


Evaluación no-honesta 
======================================== 

Correctly Classified Instances       16556               72.1677 %
Incorrectly Classified Instances      6385               27.8323 %
Kappa statistic                          0.445 
Mean absolute error                      0.2783
Root mean squared error                  0.5276
Relative absolute error                 55.6665 %
Root relative squared error            105.5145 %
Coverage of cases (0.95 level)          72.1677 %
Mean rel. region size (0.95 level)      50      %
Total Number of Instances            22941     
Recall:	 0.7216773462359967
Precision:	 0.7982294906581087

=== Confusion Matrix ===

     a     b   <-- classified as
  5448  6091 |     a = V1
   294 11108 |     b = V2
Parámetros óptimos======================================== 

|| C: 1.0054299011128027 ||
|| gamma: 2.0 ||


|| degree: 0 ||

======================================== 
=== Detailed Accuracy By Class ===

                 TP Rate  FP Rate  Precision  Recall   F-Measure  MCC      ROC Area  PRC Area  Class
                 0,472    0,026    0,949      0,472    0,631      0,515    0,723     0,713     V1
                 0,974    0,528    0,646      0,974    0,777      0,515    0,723     0,642     V2
Weighted Avg.    0,722    0,275    0,798      0,722    0,703      0,515    0,723     0,678     


Evaluación hold-out con dev 
======================================== 

Correctly Classified Instances       33567               83.2391 %
Incorrectly Classified Instances      6759               16.7609 %
Kappa statistic                          0.5235
Mean absolute error                      0.1676
Root mean squared error                  0.4094
Relative absolute error                 33.4369 %
Root relative squared error             81.6717 %
Coverage of cases (0.95 level)          83.2391 %
Mean rel. region size (0.95 level)      50      %
Total Number of Instances            40326     
Recall:	 0.8323910132420771
Precision:	 0.8426365824814233

=== Confusion Matrix ===

     a     b   <-- classified as
  5467  6126 |     a = V1
   633 28100 |     b = V2
Parámetros óptimos======================================== 

|| C: 1.0054299011128027 ||
|| gamma: 2.0 ||


|| degree: 0 ||

======================================== 
=== Detailed Accuracy By Class ===

                 TP Rate  FP Rate  Precision  Recall   F-Measure  MCC      ROC Area  PRC Area  Class
                 0,472    0,022    0,896      0,472    0,618      0,568    0,725     0,575     V1
                 0,978    0,528    0,821      0,978    0,893      0,568    0,725     0,819     V2
Weighted Avg.    0,832    0,383    0,843      0,832    0,814      0,568    0,725     0,748     


Evaluación 10FCV con dev+train 
======================================== 

Correctly Classified Instances       67134               83.2391 %
Incorrectly Classified Instances     13518               16.7609 %
Kappa statistic                          0.5235
Mean absolute error                      0.1676
Root mean squared error                  0.4094
Relative absolute error                 36.7989 %
Root relative squared error             85.7288 %
Coverage of cases (0.95 level)          83.2391 %
Mean rel. region size (0.95 level)      50      %
Total Number of Instances            80652     
Recall:	 0.8323910132420771
Precision:	 0.8426365824814233

=== Confusion Matrix ===

     a     b   <-- classified as
 10934 12252 |     a = V1
  1266 56200 |     b = V2
Parámetros óptimos======================================== 

|| C: 1.0054299011128027 ||
|| gamma: 2.0 ||


|| degree: 0 ||

======================================== 
=== Detailed Accuracy By Class ===

                 TP Rate  FP Rate  Precision  Recall   F-Measure  MCC      ROC Area  PRC Area  Class
                 0,472    0,022    0,896      0,472    0,618      0,568    0,725     0,575     V1
                 0,978    0,528    0,821      0,978    0,893      0,568    0,725     0,819     V2
Weighted Avg.    0,832    0,383    0,843      0,832    0,814      0,568    0,725     0,748     
